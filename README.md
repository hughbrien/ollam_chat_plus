# ollam_chat_plus
Generate a Chat Program 
Chat Program using Ollama and LangChain and other stuff


## Large Language Model 
- LLM Runtime Engine : Ollama 
- LLM : llama3:latest

## Application Framework
- Language: Java 
- Software Framework : LangChain

## Model Context Protocoll Services 
- Weather 
- Calendar

## Capturing Prompts and Response in Vector 
Ollama procudes results from LLM. 
A Vector is included in the response. 
How do I decode the Vector from Ollama response : deepseek-coder:33b

## Add Access to Vector Database 


## Performance Metrics

The prompt performacne data returned on each request will stored and aggregate in the system prompt 
- "total_duration": 13666294709,
- "load_duration": 41568959,
- "prompt_eval_count": 26,
- "prompt_eval_duration": 915329334,
- "eval_count": 337,
- "eval_duration": 12648089891
